{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt \n",
    "import lightgbm as lgbm\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wap(df):\n",
    "        return (df['bid_price1'] * df['ask_size1'] +\n",
    "                df['ask_price1'] * df['bid_size1']) / (df['bid_size1'] + df['ask_size1'])\n",
    "\n",
    "def wap2(df):\n",
    "    return (df['bid_price2'] * df['ask_size2'] +\n",
    "            df['ask_price2'] * df['bid_size2']) / (df['bid_size2'] + df['ask_size2'])\n",
    "\n",
    "def log_return(list_stock_prices):\n",
    "    return np.log(list_stock_prices).diff()\n",
    "\n",
    "def realized_volatility(returns):\n",
    "    return np.sqrt(np.sum(returns ** 2))\n",
    "\n",
    "def count_unique(series):\n",
    "    return len(np.unique(series))\n",
    "\n",
    "def isValidStock(i):\n",
    "    filename = \"stock_trade_train/stock_\" + str(i) + \"_train.parquet\"\n",
    "    if not os.path.exists(filename):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def RMSPEMetric():\n",
    "\n",
    "    def RMSPE(yhat, dtrain):\n",
    "        y = dtrain.get_label()\n",
    "        elements = ((y - yhat) / y) ** 2\n",
    "        return 'RMSPE', float(np.sqrt(np.sum(elements) / len(y))), False\n",
    "\n",
    "    return RMSPE\n",
    "\n",
    "def RMSPE(y, y_hat):\n",
    "    elements = ((y - y_hat) / y) ** 2\n",
    "    return float(np.sqrt(np.sum(elements) / len(y)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def book_predictors(stock_id, train_or_test):\n",
    "    stock_data = pd.read_parquet('stock_book_' + train_or_test + '/stock_' + str(stock_id) + '_' + train_or_test + '.parquet')\n",
    "    stock_data['wap'] = wap(stock_data)\n",
    "    stock_data['log_return'] = stock_data.groupby('time_id')['wap'].apply(log_return)\n",
    "    stock_data['wap2'] = wap2(stock_data)\n",
    "    stock_data['log_return2'] = stock_data.groupby('time_id')['wap2'].apply(log_return)\n",
    "    stock_data['wap_offset'] = abs(stock_data['wap'] - stock_data['wap2'])\n",
    "    stock_data['price_spread'] = (stock_data['ask_price1'] - stock_data['bid_price1']) / ((stock_data['ask_price1'] + stock_data['bid_price1']) / 2)\n",
    "    stock_data['bid_spread'] = stock_data['bid_price1'] - stock_data['bid_price2']\n",
    "    stock_data['ask_spread'] = stock_data['ask_price1'] - stock_data['ask_price2']\n",
    "    stock_data['total_volume'] = (stock_data['ask_size1'] + stock_data['ask_size2']) + (stock_data['bid_size1'] + stock_data['bid_size2'])\n",
    "    stock_data['volume_imbalance'] = abs((stock_data['ask_size1'] + stock_data['ask_size2']) - (stock_data['bid_size1'] + stock_data['bid_size2']))\n",
    "\n",
    "    create_feature_dict = {\n",
    "            'log_return':[realized_volatility],\n",
    "            'log_return2':[realized_volatility],\n",
    "            'wap_offset':[np.mean],\n",
    "            'price_spread':[np.mean],\n",
    "            'bid_spread':[np.mean],\n",
    "            'ask_spread':[np.mean],\n",
    "            'volume_imbalance':[np.mean],\n",
    "            'total_volume':[np.mean],\n",
    "            'wap':[np.mean],\n",
    "    }\n",
    "\n",
    "    result = pd.DataFrame(stock_data.groupby(['time_id']).agg(create_feature_dict)).reset_index()\n",
    "    result.columns = result.columns.map('_'.join).str.strip('_')\n",
    "\n",
    "    return result\n",
    "\n",
    "def trade_predictors(stock_id, train_or_test):\n",
    "    stock_data = pd.read_parquet('stock_trade_' + train_or_test + '/stock_' + str(stock_id) + '_' + train_or_test + '.parquet')\n",
    "\n",
    "    stock_data['log_return'] = stock_data.groupby('time_id')['price'].apply(log_return)\n",
    "    \n",
    "    \n",
    "    aggregate_dictionary = {\n",
    "        'log_return':[realized_volatility],\n",
    "        'seconds_in_bucket':[count_unique],\n",
    "        'size':[np.sum],\n",
    "        'order_count':[np.mean],\n",
    "    }\n",
    "\n",
    "    result = pd.DataFrame(stock_data.groupby('time_id').agg(aggregate_dictionary)).reset_index()\n",
    "    result.columns = result.columns.map('_'.join).str.strip('_')\n",
    "    return result\n",
    "\n",
    "def target(stock_id, train_or_test):\n",
    "    result = pd.read_parquet('target_data/target_' + train_or_test + '.parquet')\n",
    "    result = result.loc[result['stock_id'] == stock_id]\n",
    "    result = result.drop(['stock_id'], axis = 1)\n",
    "    return result\n",
    "\n",
    "def generate_data(stock_id, train_or_test):\n",
    "    result = pd.merge(target(stock_id, train_or_test), book_predictors(stock_id, train_or_test), on='time_id', how='left')\n",
    "    result = pd.merge(result, trade_predictors(stock_id, train_or_test), on='time_id', how='left')\n",
    "    result = result.dropna()\n",
    "    return result\n",
    "\n",
    "def generate_train_and_test(stock_id):\n",
    "    train = generate_data(stock_id, 'train')\n",
    "    test = generate_data(stock_id, 'test')\n",
    "\n",
    "    X_train = train.drop(['target', 'time_id'], axis = 1)\n",
    "    X_test = test.drop(['target', 'time_id'], axis = 1)\n",
    "\n",
    "    y_train = train['target']\n",
    "    y_test = test['target']\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting combined Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "total_size = 0\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "X_train = pd.DataFrame()\n",
    "X_test = pd.DataFrame()\n",
    "y_train = pd.DataFrame()\n",
    "y_test = pd.DataFrame()\n",
    "\n",
    "for i in range(127):\n",
    "    if not isValidStock(i):\n",
    "        continue\n",
    "\n",
    "    a, b, c, d = generate_train_and_test(i)\n",
    "\n",
    "    X_train = pd.concat([X_train, a])\n",
    "    X_test = pd.concat([X_test, b])\n",
    "    y_train = pd.concat([y_train, c])\n",
    "    y_test = pd.concat([y_test, d])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmspe= []\n",
    "\n",
    "for i in range(100):\n",
    "    knn = KNeighborsRegressor(n_neighbors=i + 1)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_hat = pd.DataFrame(knn.predict(X_test))\n",
    "\n",
    "    rmspe.append(RMSPE(y_test, y_hat))\n",
    "\n",
    "optimal = rmspe.index(min(rmspe)) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7988844043032836"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=optimal)\n",
    "knn.fit(X_train, y_train)\n",
    "y_hat = pd.DataFrame(knn.predict(X_test))\n",
    "\n",
    "RMSPE(y_test, y_hat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d41f633da6a0ed462606ff387ac8d93faacd97ec55d72fd1ffe37702897b9b90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
