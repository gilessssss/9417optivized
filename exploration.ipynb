{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\kevin\\Desktop\\UNI\\2022 T2\\COMP9417\\Optiver\\9417optivized\\exploration.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kevin/Desktop/UNI/2022%20T2/COMP9417/Optiver/9417optivized/exploration.ipynb#ch0000000?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcollections\u001b[39;00m \u001b[39mimport\u001b[39;00m Counter\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kevin/Desktop/UNI/2022%20T2/COMP9417/Optiver/9417optivized/exploration.ipynb#ch0000000?line=5'>6</a>\u001b[0m warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/kevin/Desktop/UNI/2022%20T2/COMP9417/Optiver/9417optivized/exploration.ipynb#ch0000000?line=6'>7</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mplotly\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexpress\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpx\u001b[39;00m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kevin/Desktop/UNI/2022%20T2/COMP9417/Optiver/9417optivized/exploration.ipynb#ch0000000?line=7'>8</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kevin/Desktop/UNI/2022%20T2/COMP9417/Optiver/9417optivized/exploration.ipynb#ch0000000?line=8'>9</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m \n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import glob \n",
    "import warnings \n",
    "from collections import Counter\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import plotly.express as px \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "import lightgbm as lgbm \n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import math\n",
    "import os \n",
    "import random\n",
    "import torch \n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import torch.nn as nn\n",
    "#from transformers import AdamW\n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "from colorama import Fore , Style\n",
    "r__=Fore.RED\n",
    "g__=Fore.GREEN\n",
    "st__=Style.RESET_ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "r__=Fore.RED\n",
    "g__=Fore.GREEN\n",
    "st__=Style.RESET_ALL\n",
    "def wap(row) :\n",
    "    denom = row.ask_size1 + row.bid_size1\n",
    "    return ((row.bid_price1 * row.ask_size1 + row.ask_price1 * row.bid_size1)/denom)\n",
    "def log_return(list_prices):\n",
    "    return np.log(list_prices).diff()\n",
    "def realized_volatility(series_log_return):\n",
    "    return np.sqrt(np.sum(series_log_return**2))\n",
    "def custom_loss(ytrue,ypred) :\n",
    "    squared_residual = (ytrue-ypred)**2/ytrue\n",
    "    grad = squared_residual\n",
    "    hess = np.ones(len(ytrue))\n",
    "    \n",
    "    return grad,hess\n",
    "def rmspe(y_true, y_pred):\n",
    "    return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))\n",
    "def feval_RMSPE(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    return 'RMSPE', round(rmspe(y_true = labels, y_pred = preds),5), False\n",
    "def custom_rmspe_valid(y_true, y_pred):\n",
    "    residual = (y_true - y_pred).astype(\"float\")\n",
    "    residual = residual ** 2 / y_true\n",
    "    residual = np.mean(residual)\n",
    "    return \"eval_RMSPE\", math.sqrt(residual), False\n",
    "def simple_volatility(series_prix):\n",
    "    mx = np.max(series_prix)\n",
    "    mn = np.min(series_prix)\n",
    "    moy = np.mean(series_prix)\n",
    "    vol = (moy-mn)/(mx-mn)\n",
    "    return vol\n",
    "def count_unique(series):\n",
    "    return len(np.unique(series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "NotImplemented: Support for codec 'snappy' not built",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\kevin\\Desktop\\UNI\\2022 T2\\COMP9417\\Optiver\\9417optivized\\exploration.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/kevin/Desktop/UNI/2022%20T2/COMP9417/Optiver/9417optivized/exploration.ipynb#ch0000001?line=0'>1</a>\u001b[0m train \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_parquet(\u001b[39m\"\u001b[39;49m\u001b[39mtarget_data/target_train.parquet\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kevin/Desktop/UNI/2022%20T2/COMP9417/Optiver/9417optivized/exploration.ipynb#ch0000001?line=1'>2</a>\u001b[0m train\n",
      "File \u001b[1;32mc:\\Users\\kevin\\anaconda3\\lib\\site-packages\\pandas\\io\\parquet.py:493\u001b[0m, in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[39mLoad a parquet object from the file path, returning a DataFrame.\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    489\u001b[0m \u001b[39mDataFrame\u001b[39;00m\n\u001b[0;32m    490\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    491\u001b[0m impl \u001b[39m=\u001b[39m get_engine(engine)\n\u001b[1;32m--> 493\u001b[0m \u001b[39mreturn\u001b[39;00m impl\u001b[39m.\u001b[39mread(\n\u001b[0;32m    494\u001b[0m     path,\n\u001b[0;32m    495\u001b[0m     columns\u001b[39m=\u001b[39mcolumns,\n\u001b[0;32m    496\u001b[0m     storage_options\u001b[39m=\u001b[39mstorage_options,\n\u001b[0;32m    497\u001b[0m     use_nullable_dtypes\u001b[39m=\u001b[39muse_nullable_dtypes,\n\u001b[0;32m    498\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    499\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\kevin\\anaconda3\\lib\\site-packages\\pandas\\io\\parquet.py:240\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[1;34m(self, path, columns, use_nullable_dtypes, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m path_or_handle, handles, kwargs[\u001b[39m\"\u001b[39m\u001b[39mfilesystem\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m _get_path_or_handle(\n\u001b[0;32m    234\u001b[0m     path,\n\u001b[0;32m    235\u001b[0m     kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mfilesystem\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[0;32m    236\u001b[0m     storage_options\u001b[39m=\u001b[39mstorage_options,\n\u001b[0;32m    237\u001b[0m     mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    238\u001b[0m )\n\u001b[0;32m    239\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 240\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi\u001b[39m.\u001b[39mparquet\u001b[39m.\u001b[39mread_table(\n\u001b[0;32m    241\u001b[0m         path_or_handle, columns\u001b[39m=\u001b[39mcolumns, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    242\u001b[0m     )\u001b[39m.\u001b[39mto_pandas(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mto_pandas_kwargs)\n\u001b[0;32m    243\u001b[0m     \u001b[39mif\u001b[39;00m manager \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    244\u001b[0m         result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39m_as_manager(\u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\kevin\\anaconda3\\lib\\site-packages\\pyarrow\\parquet.py:1703\u001b[0m, in \u001b[0;36mread_table\u001b[1;34m(source, columns, use_threads, metadata, use_pandas_metadata, memory_map, read_dictionary, filesystem, filters, buffer_size, partitioning, use_legacy_dataset, ignore_prefixes)\u001b[0m\n\u001b[0;32m   1698\u001b[0m         \u001b[39m# TODO test that source is not a directory or a list\u001b[39;00m\n\u001b[0;32m   1699\u001b[0m         dataset \u001b[39m=\u001b[39m ParquetFile(\n\u001b[0;32m   1700\u001b[0m             source, metadata\u001b[39m=\u001b[39mmetadata, read_dictionary\u001b[39m=\u001b[39mread_dictionary,\n\u001b[0;32m   1701\u001b[0m             memory_map\u001b[39m=\u001b[39mmemory_map, buffer_size\u001b[39m=\u001b[39mbuffer_size)\n\u001b[1;32m-> 1703\u001b[0m     \u001b[39mreturn\u001b[39;00m dataset\u001b[39m.\u001b[39;49mread(columns\u001b[39m=\u001b[39;49mcolumns, use_threads\u001b[39m=\u001b[39;49muse_threads,\n\u001b[0;32m   1704\u001b[0m                         use_pandas_metadata\u001b[39m=\u001b[39;49muse_pandas_metadata)\n\u001b[0;32m   1706\u001b[0m \u001b[39mif\u001b[39;00m ignore_prefixes \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1707\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1708\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m'\u001b[39m\u001b[39mignore_prefixes\u001b[39m\u001b[39m'\u001b[39m\u001b[39m keyword is only supported when \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1709\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39muse_legacy_dataset=False\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\kevin\\anaconda3\\lib\\site-packages\\pyarrow\\parquet.py:1580\u001b[0m, in \u001b[0;36m_ParquetDatasetV2.read\u001b[1;34m(self, columns, use_threads, use_pandas_metadata)\u001b[0m\n\u001b[0;32m   1575\u001b[0m     \u001b[39mif\u001b[39;00m use_threads:\n\u001b[0;32m   1576\u001b[0m         \u001b[39m# Allow per-column parallelism; would otherwise cause\u001b[39;00m\n\u001b[0;32m   1577\u001b[0m         \u001b[39m# contention in the presence of per-file parallelism.\u001b[39;00m\n\u001b[0;32m   1578\u001b[0m         use_threads \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1580\u001b[0m table \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset\u001b[39m.\u001b[39;49mto_table(\n\u001b[0;32m   1581\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns, \u001b[39mfilter\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_filter_expression,\n\u001b[0;32m   1582\u001b[0m     use_threads\u001b[39m=\u001b[39;49muse_threads\n\u001b[0;32m   1583\u001b[0m )\n\u001b[0;32m   1585\u001b[0m \u001b[39m# if use_pandas_metadata, restore the pandas metadata (which gets\u001b[39;00m\n\u001b[0;32m   1586\u001b[0m \u001b[39m# lost if doing a specific `columns` selection in to_table)\u001b[39;00m\n\u001b[0;32m   1587\u001b[0m \u001b[39mif\u001b[39;00m use_pandas_metadata:\n",
      "File \u001b[1;32mc:\\Users\\kevin\\anaconda3\\lib\\site-packages\\pyarrow\\_dataset.pyx:372\u001b[0m, in \u001b[0;36mpyarrow._dataset.Dataset.to_table\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\kevin\\anaconda3\\lib\\site-packages\\pyarrow\\_dataset.pyx:2266\u001b[0m, in \u001b[0;36mpyarrow._dataset.Scanner.to_table\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\kevin\\anaconda3\\lib\\site-packages\\pyarrow\\error.pxi:122\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\kevin\\anaconda3\\lib\\site-packages\\pyarrow\\error.pxi:99\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: NotImplemented: Support for codec 'snappy' not built"
     ]
    }
   ],
   "source": [
    "train = pd.read_parquet(\"target_data/target_train.parquet\")\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>bid_price1</th>\n",
       "      <th>ask_price1</th>\n",
       "      <th>bid_price2</th>\n",
       "      <th>ask_price2</th>\n",
       "      <th>bid_size1</th>\n",
       "      <th>ask_size1</th>\n",
       "      <th>bid_size2</th>\n",
       "      <th>ask_size2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000754</td>\n",
       "      <td>1.001542</td>\n",
       "      <td>1.000689</td>\n",
       "      <td>1.001607</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000754</td>\n",
       "      <td>1.001673</td>\n",
       "      <td>1.000689</td>\n",
       "      <td>1.001739</td>\n",
       "      <td>26</td>\n",
       "      <td>60</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000754</td>\n",
       "      <td>1.001411</td>\n",
       "      <td>1.000623</td>\n",
       "      <td>1.001476</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000754</td>\n",
       "      <td>1.001542</td>\n",
       "      <td>1.000689</td>\n",
       "      <td>1.001607</td>\n",
       "      <td>125</td>\n",
       "      <td>25</td>\n",
       "      <td>126</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000754</td>\n",
       "      <td>1.001476</td>\n",
       "      <td>1.000623</td>\n",
       "      <td>1.001542</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507527</th>\n",
       "      <td>32767</td>\n",
       "      <td>588</td>\n",
       "      <td>0.998911</td>\n",
       "      <td>0.999109</td>\n",
       "      <td>0.998812</td>\n",
       "      <td>0.999208</td>\n",
       "      <td>126</td>\n",
       "      <td>42</td>\n",
       "      <td>101</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507528</th>\n",
       "      <td>32767</td>\n",
       "      <td>589</td>\n",
       "      <td>0.998911</td>\n",
       "      <td>0.999109</td>\n",
       "      <td>0.998812</td>\n",
       "      <td>0.999208</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "      <td>101</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507529</th>\n",
       "      <td>32767</td>\n",
       "      <td>591</td>\n",
       "      <td>0.998911</td>\n",
       "      <td>0.999109</td>\n",
       "      <td>0.998812</td>\n",
       "      <td>0.999208</td>\n",
       "      <td>126</td>\n",
       "      <td>226</td>\n",
       "      <td>101</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507530</th>\n",
       "      <td>32767</td>\n",
       "      <td>592</td>\n",
       "      <td>0.998911</td>\n",
       "      <td>0.999109</td>\n",
       "      <td>0.998812</td>\n",
       "      <td>0.999208</td>\n",
       "      <td>226</td>\n",
       "      <td>225</td>\n",
       "      <td>101</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507531</th>\n",
       "      <td>32767</td>\n",
       "      <td>593</td>\n",
       "      <td>0.998911</td>\n",
       "      <td>0.999109</td>\n",
       "      <td>0.998812</td>\n",
       "      <td>0.999208</td>\n",
       "      <td>125</td>\n",
       "      <td>225</td>\n",
       "      <td>101</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1507532 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         time_id  seconds_in_bucket  bid_price1  ask_price1  bid_price2  \\\n",
       "0              5                  0    1.000754    1.001542    1.000689   \n",
       "1              5                  1    1.000754    1.001673    1.000689   \n",
       "2              5                  2    1.000754    1.001411    1.000623   \n",
       "3              5                  3    1.000754    1.001542    1.000689   \n",
       "4              5                  4    1.000754    1.001476    1.000623   \n",
       "...          ...                ...         ...         ...         ...   \n",
       "1507527    32767                588    0.998911    0.999109    0.998812   \n",
       "1507528    32767                589    0.998911    0.999109    0.998812   \n",
       "1507529    32767                591    0.998911    0.999109    0.998812   \n",
       "1507530    32767                592    0.998911    0.999109    0.998812   \n",
       "1507531    32767                593    0.998911    0.999109    0.998812   \n",
       "\n",
       "         ask_price2  bid_size1  ask_size1  bid_size2  ask_size2  \n",
       "0          1.001607          1         25         25        100  \n",
       "1          1.001739         26         60         25        100  \n",
       "2          1.001476          1         25         25        125  \n",
       "3          1.001607        125         25        126         36  \n",
       "4          1.001542        100        100         25         25  \n",
       "...             ...        ...        ...        ...        ...  \n",
       "1507527    0.999208        126         42        101        100  \n",
       "1507528    0.999208        126        126        101        200  \n",
       "1507529    0.999208        126        226        101        200  \n",
       "1507530    0.999208        226        225        101        100  \n",
       "1507531    0.999208        125        225        101        100  \n",
       "\n",
       "[1507532 rows x 10 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_train_stock_id_1 = pd.read_parquet(\"optiver_raw_data/book_train.parquet/stock_id=1\")\n",
    "book_train_stock_id_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "NotImplemented: Support for codec 'snappy' not built",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\kevin\\Desktop\\UNI\\2022 T2\\COMP9417\\Optiver\\9417optivized\\exploration.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/kevin/Desktop/UNI/2022%20T2/COMP9417/Optiver/9417optivized/exploration.ipynb#ch0000006?line=0'>1</a>\u001b[0m train \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_parquet(\u001b[39m\"\u001b[39;49m\u001b[39mtarget_data/target_train.parquet\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kevin/Desktop/UNI/2022%20T2/COMP9417/Optiver/9417optivized/exploration.ipynb#ch0000006?line=1'>2</a>\u001b[0m train\n",
      "File \u001b[1;32mc:\\Users\\kevin\\anaconda3\\lib\\site-packages\\pandas\\io\\parquet.py:493\u001b[0m, in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[39mLoad a parquet object from the file path, returning a DataFrame.\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    489\u001b[0m \u001b[39mDataFrame\u001b[39;00m\n\u001b[0;32m    490\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    491\u001b[0m impl \u001b[39m=\u001b[39m get_engine(engine)\n\u001b[1;32m--> 493\u001b[0m \u001b[39mreturn\u001b[39;00m impl\u001b[39m.\u001b[39mread(\n\u001b[0;32m    494\u001b[0m     path,\n\u001b[0;32m    495\u001b[0m     columns\u001b[39m=\u001b[39mcolumns,\n\u001b[0;32m    496\u001b[0m     storage_options\u001b[39m=\u001b[39mstorage_options,\n\u001b[0;32m    497\u001b[0m     use_nullable_dtypes\u001b[39m=\u001b[39muse_nullable_dtypes,\n\u001b[0;32m    498\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    499\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\kevin\\anaconda3\\lib\\site-packages\\pandas\\io\\parquet.py:240\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[1;34m(self, path, columns, use_nullable_dtypes, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m path_or_handle, handles, kwargs[\u001b[39m\"\u001b[39m\u001b[39mfilesystem\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m _get_path_or_handle(\n\u001b[0;32m    234\u001b[0m     path,\n\u001b[0;32m    235\u001b[0m     kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mfilesystem\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[0;32m    236\u001b[0m     storage_options\u001b[39m=\u001b[39mstorage_options,\n\u001b[0;32m    237\u001b[0m     mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    238\u001b[0m )\n\u001b[0;32m    239\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 240\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi\u001b[39m.\u001b[39mparquet\u001b[39m.\u001b[39mread_table(\n\u001b[0;32m    241\u001b[0m         path_or_handle, columns\u001b[39m=\u001b[39mcolumns, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    242\u001b[0m     )\u001b[39m.\u001b[39mto_pandas(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mto_pandas_kwargs)\n\u001b[0;32m    243\u001b[0m     \u001b[39mif\u001b[39;00m manager \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    244\u001b[0m         result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39m_as_manager(\u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\kevin\\anaconda3\\lib\\site-packages\\pyarrow\\parquet.py:1703\u001b[0m, in \u001b[0;36mread_table\u001b[1;34m(source, columns, use_threads, metadata, use_pandas_metadata, memory_map, read_dictionary, filesystem, filters, buffer_size, partitioning, use_legacy_dataset, ignore_prefixes)\u001b[0m\n\u001b[0;32m   1698\u001b[0m         \u001b[39m# TODO test that source is not a directory or a list\u001b[39;00m\n\u001b[0;32m   1699\u001b[0m         dataset \u001b[39m=\u001b[39m ParquetFile(\n\u001b[0;32m   1700\u001b[0m             source, metadata\u001b[39m=\u001b[39mmetadata, read_dictionary\u001b[39m=\u001b[39mread_dictionary,\n\u001b[0;32m   1701\u001b[0m             memory_map\u001b[39m=\u001b[39mmemory_map, buffer_size\u001b[39m=\u001b[39mbuffer_size)\n\u001b[1;32m-> 1703\u001b[0m     \u001b[39mreturn\u001b[39;00m dataset\u001b[39m.\u001b[39;49mread(columns\u001b[39m=\u001b[39;49mcolumns, use_threads\u001b[39m=\u001b[39;49muse_threads,\n\u001b[0;32m   1704\u001b[0m                         use_pandas_metadata\u001b[39m=\u001b[39;49muse_pandas_metadata)\n\u001b[0;32m   1706\u001b[0m \u001b[39mif\u001b[39;00m ignore_prefixes \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1707\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1708\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m'\u001b[39m\u001b[39mignore_prefixes\u001b[39m\u001b[39m'\u001b[39m\u001b[39m keyword is only supported when \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1709\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39muse_legacy_dataset=False\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\kevin\\anaconda3\\lib\\site-packages\\pyarrow\\parquet.py:1580\u001b[0m, in \u001b[0;36m_ParquetDatasetV2.read\u001b[1;34m(self, columns, use_threads, use_pandas_metadata)\u001b[0m\n\u001b[0;32m   1575\u001b[0m     \u001b[39mif\u001b[39;00m use_threads:\n\u001b[0;32m   1576\u001b[0m         \u001b[39m# Allow per-column parallelism; would otherwise cause\u001b[39;00m\n\u001b[0;32m   1577\u001b[0m         \u001b[39m# contention in the presence of per-file parallelism.\u001b[39;00m\n\u001b[0;32m   1578\u001b[0m         use_threads \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1580\u001b[0m table \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset\u001b[39m.\u001b[39;49mto_table(\n\u001b[0;32m   1581\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns, \u001b[39mfilter\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_filter_expression,\n\u001b[0;32m   1582\u001b[0m     use_threads\u001b[39m=\u001b[39;49muse_threads\n\u001b[0;32m   1583\u001b[0m )\n\u001b[0;32m   1585\u001b[0m \u001b[39m# if use_pandas_metadata, restore the pandas metadata (which gets\u001b[39;00m\n\u001b[0;32m   1586\u001b[0m \u001b[39m# lost if doing a specific `columns` selection in to_table)\u001b[39;00m\n\u001b[0;32m   1587\u001b[0m \u001b[39mif\u001b[39;00m use_pandas_metadata:\n",
      "File \u001b[1;32mc:\\Users\\kevin\\anaconda3\\lib\\site-packages\\pyarrow\\_dataset.pyx:372\u001b[0m, in \u001b[0;36mpyarrow._dataset.Dataset.to_table\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\kevin\\anaconda3\\lib\\site-packages\\pyarrow\\_dataset.pyx:2266\u001b[0m, in \u001b[0;36mpyarrow._dataset.Scanner.to_table\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\kevin\\anaconda3\\lib\\site-packages\\pyarrow\\error.pxi:122\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\kevin\\anaconda3\\lib\\site-packages\\pyarrow\\error.pxi:99\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: NotImplemented: Support for codec 'snappy' not built"
     ]
    }
   ],
   "source": [
    "train = pd.read_parquet(\"target_data/target_train.parquet\")\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "NotImplemented: Support for codec 'snappy' not built",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\kevin\\Desktop\\UNI\\2022 T2\\COMP9417\\Optiver\\9417optivized\\exploration.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/kevin/Desktop/UNI/2022%20T2/COMP9417/Optiver/9417optivized/exploration.ipynb#ch0000008?line=0'>1</a>\u001b[0m book_train_stock_id_1 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_parquet(\u001b[39m\"\u001b[39;49m\u001b[39mstock_train/stock_0_train.parquet\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kevin/Desktop/UNI/2022%20T2/COMP9417/Optiver/9417optivized/exploration.ipynb#ch0000008?line=1'>2</a>\u001b[0m book_train_stock_id_1\n",
      "File \u001b[1;32mc:\\Users\\kevin\\anaconda3\\lib\\site-packages\\pandas\\io\\parquet.py:493\u001b[0m, in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[39mLoad a parquet object from the file path, returning a DataFrame.\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    489\u001b[0m \u001b[39mDataFrame\u001b[39;00m\n\u001b[0;32m    490\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    491\u001b[0m impl \u001b[39m=\u001b[39m get_engine(engine)\n\u001b[1;32m--> 493\u001b[0m \u001b[39mreturn\u001b[39;00m impl\u001b[39m.\u001b[39mread(\n\u001b[0;32m    494\u001b[0m     path,\n\u001b[0;32m    495\u001b[0m     columns\u001b[39m=\u001b[39mcolumns,\n\u001b[0;32m    496\u001b[0m     storage_options\u001b[39m=\u001b[39mstorage_options,\n\u001b[0;32m    497\u001b[0m     use_nullable_dtypes\u001b[39m=\u001b[39muse_nullable_dtypes,\n\u001b[0;32m    498\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    499\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\kevin\\anaconda3\\lib\\site-packages\\pandas\\io\\parquet.py:240\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[1;34m(self, path, columns, use_nullable_dtypes, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m path_or_handle, handles, kwargs[\u001b[39m\"\u001b[39m\u001b[39mfilesystem\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m _get_path_or_handle(\n\u001b[0;32m    234\u001b[0m     path,\n\u001b[0;32m    235\u001b[0m     kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mfilesystem\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[0;32m    236\u001b[0m     storage_options\u001b[39m=\u001b[39mstorage_options,\n\u001b[0;32m    237\u001b[0m     mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    238\u001b[0m )\n\u001b[0;32m    239\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 240\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi\u001b[39m.\u001b[39mparquet\u001b[39m.\u001b[39mread_table(\n\u001b[0;32m    241\u001b[0m         path_or_handle, columns\u001b[39m=\u001b[39mcolumns, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    242\u001b[0m     )\u001b[39m.\u001b[39mto_pandas(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mto_pandas_kwargs)\n\u001b[0;32m    243\u001b[0m     \u001b[39mif\u001b[39;00m manager \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    244\u001b[0m         result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39m_as_manager(\u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\kevin\\anaconda3\\lib\\site-packages\\pyarrow\\parquet.py:1703\u001b[0m, in \u001b[0;36mread_table\u001b[1;34m(source, columns, use_threads, metadata, use_pandas_metadata, memory_map, read_dictionary, filesystem, filters, buffer_size, partitioning, use_legacy_dataset, ignore_prefixes)\u001b[0m\n\u001b[0;32m   1698\u001b[0m         \u001b[39m# TODO test that source is not a directory or a list\u001b[39;00m\n\u001b[0;32m   1699\u001b[0m         dataset \u001b[39m=\u001b[39m ParquetFile(\n\u001b[0;32m   1700\u001b[0m             source, metadata\u001b[39m=\u001b[39mmetadata, read_dictionary\u001b[39m=\u001b[39mread_dictionary,\n\u001b[0;32m   1701\u001b[0m             memory_map\u001b[39m=\u001b[39mmemory_map, buffer_size\u001b[39m=\u001b[39mbuffer_size)\n\u001b[1;32m-> 1703\u001b[0m     \u001b[39mreturn\u001b[39;00m dataset\u001b[39m.\u001b[39;49mread(columns\u001b[39m=\u001b[39;49mcolumns, use_threads\u001b[39m=\u001b[39;49muse_threads,\n\u001b[0;32m   1704\u001b[0m                         use_pandas_metadata\u001b[39m=\u001b[39;49muse_pandas_metadata)\n\u001b[0;32m   1706\u001b[0m \u001b[39mif\u001b[39;00m ignore_prefixes \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1707\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1708\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m'\u001b[39m\u001b[39mignore_prefixes\u001b[39m\u001b[39m'\u001b[39m\u001b[39m keyword is only supported when \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1709\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39muse_legacy_dataset=False\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\kevin\\anaconda3\\lib\\site-packages\\pyarrow\\parquet.py:1580\u001b[0m, in \u001b[0;36m_ParquetDatasetV2.read\u001b[1;34m(self, columns, use_threads, use_pandas_metadata)\u001b[0m\n\u001b[0;32m   1575\u001b[0m     \u001b[39mif\u001b[39;00m use_threads:\n\u001b[0;32m   1576\u001b[0m         \u001b[39m# Allow per-column parallelism; would otherwise cause\u001b[39;00m\n\u001b[0;32m   1577\u001b[0m         \u001b[39m# contention in the presence of per-file parallelism.\u001b[39;00m\n\u001b[0;32m   1578\u001b[0m         use_threads \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1580\u001b[0m table \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset\u001b[39m.\u001b[39;49mto_table(\n\u001b[0;32m   1581\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns, \u001b[39mfilter\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_filter_expression,\n\u001b[0;32m   1582\u001b[0m     use_threads\u001b[39m=\u001b[39;49muse_threads\n\u001b[0;32m   1583\u001b[0m )\n\u001b[0;32m   1585\u001b[0m \u001b[39m# if use_pandas_metadata, restore the pandas metadata (which gets\u001b[39;00m\n\u001b[0;32m   1586\u001b[0m \u001b[39m# lost if doing a specific `columns` selection in to_table)\u001b[39;00m\n\u001b[0;32m   1587\u001b[0m \u001b[39mif\u001b[39;00m use_pandas_metadata:\n",
      "File \u001b[1;32mc:\\Users\\kevin\\anaconda3\\lib\\site-packages\\pyarrow\\_dataset.pyx:372\u001b[0m, in \u001b[0;36mpyarrow._dataset.Dataset.to_table\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\kevin\\anaconda3\\lib\\site-packages\\pyarrow\\_dataset.pyx:2266\u001b[0m, in \u001b[0;36mpyarrow._dataset.Scanner.to_table\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\kevin\\anaconda3\\lib\\site-packages\\pyarrow\\error.pxi:122\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\kevin\\anaconda3\\lib\\site-packages\\pyarrow\\error.pxi:99\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: NotImplemented: Support for codec 'snappy' not built"
     ]
    }
   ],
   "source": [
    "book_train_stock_id_1 = pd.read_parquet(\"stock_train/stock_0_train.parquet\")\n",
    "book_train_stock_id_1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ebd44a32489bc3390e317f335d60ec31949424b9aac8495ac50fd9a00e8750e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
